<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Title</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <script src="libs/face-api.js" ></script>
</head>
<body>

    <video onplay="onPlay(this)"  width="640px" height="480px" style="position:absolute;top:0; left:0" id="inputVideo" autoplay muted></video>
    <canvas id="overlay" width="640px" height="480px"  style="position:absolute;top:0; left:0 ;z-index:3" />
<!---->
</body>
<script>
    const mtcnnForwardParams = {
        // limiting the search space to larger faces for webcam detection
        minFaceSize: 100
    }
    async function onPlay(videoEl){
        let canvas = document.getElementById('overlay');
        var context = canvas.getContext('2d');

        const options = new faceapi.MtcnnOptions(mtcnnForwardParams)
        const input = document.getElementById('inputVideo')
        const fullFaceDescriptions = await faceapi.detectAllFaces(input, options).withFaceLandmarks().withFaceDescriptors()

        const labels = ['ref1']
        const labeledFaceDescriptors = await Promise.all(
            labels.map(async label => {
                context.clearRect(0, 0, canvas.width, canvas.height);

                // fetch image data from urls and convert blob to HTMLImage element
                const imgUrl = `images/${label}.png`
                const img = await faceapi.fetchImage(imgUrl)

                // detect the face with the highest score in the image and compute it's landmarks and face descriptor
                const fullFaceDescription = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor()

                if (!fullFaceDescription) {
                    throw new Error(`no faces detected for ${label}`)
                }

                const faceDescriptors = [fullFaceDescription.descriptor]
                return new faceapi.LabeledFaceDescriptors(label, faceDescriptors)
            })
        )
        const maxDescriptorDistance = 0.6;
        const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, maxDescriptorDistance)

        const results = fullFaceDescriptions.map(fd => faceMatcher.findBestMatch(fd.descriptor))
        results.forEach((bestMatch, i) => {
            const box = fullFaceDescriptions[i].detection.box
            const text = bestMatch.toString()
            const drawBox = new faceapi.draw.DrawBox(box, { label: text })
            drawBox.draw(canvas);
            console.log(bestMatch)
            if(bestMatch._label==='ref1'){
                console.log("Hello ref1")
                return null;
            }
        })
        setTimeout(() => onPlay(videoEl))
    }
    async function runDetection(){
        await faceapi.loadMtcnnModel('model/')
        await faceapi.loadFaceRecognitionModel('model/')
        let minConfidence = 0.5
        await faceapi.loadFaceLandmarkModel('model/')
        await faceapi.loadSsdMobilenetv1Model('model/')
        const videoEl = document.getElementById('inputVideo')
        navigator.getUserMedia(
            { video: {} },
            stream => videoEl.srcObject = stream,
            err => console.error(err)
        )
    }
$(document).ready(function () {

    runDetection();
})
</script>
</html>